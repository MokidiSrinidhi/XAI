{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7ylvDGlUidsrDo8avPig1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MokidiSrinidhi/XAI/blob/main/XAI_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import zipfile\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score, roc_curve\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import seaborn as sns\n",
        "\n",
        "# --- 1. Setup (Run this in Google Colab) ---\n",
        "# This section is for downloading and unzipping the data.\n",
        "# You will need to get the Kaggle API credentials.\n",
        "\n",
        "# !pip install kaggle --quiet\n",
        "\n",
        "# # Set up Kaggle API token\n",
        "# # 1. Go to your Kaggle account, click your profile picture\n",
        "# # 2. Go to \"Account\" -> \"API\" -> \"Create New API Token\"\n",
        "# # 3. This will download 'kaggle.json'. Upload it to your Colab session.\n",
        "# !mkdir -p ~/.kaggle\n",
        "# !cp kaggle.json ~/.kaggle/\n",
        "# !chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# # --- IMPORTANT ---\n",
        "# # The dataset link you provided (pacificrm/skindiseasedataset) seems broken or private.\n",
        "# # I will use a different, popular skin disease dataset as an example:\n",
        "# # \"Skin Cancer MNIST: HAM10000\" (URL: https://www.kaggle.com/datasets/kmader/skin-cancer-mnist-ham10000)\n",
        "# # This dataset is in CSV format with image IDs, so the loading logic is different.\n",
        "\n",
        "# # Let's use a dataset that is already in image folders, as your instructions imply.\n",
        "# # Example: \"Skin Disease Dataset\" (URL: https://www.kaggle.com/datasets/prashantmishra158/skin-disease-dataset)\n",
        "# print(\"Downloading dataset...\")\n",
        "# !kaggle datasets download -d prashantmishra158/skin-disease-dataset --unzip -q\n",
        "\n",
        "print(\"--- Setup Complete (Simulated for this environment) ---\")\n",
        "print(\"In a real environment (Colab), the above commands would download and unzip the data.\")\n",
        "\n",
        "# --- 2. Data Preprocessing & Loading ---\n",
        "\n",
        "# Define paths and parameters\n",
        "# ASSUMPTION: The data is unzipped into 'train_set' and 'test_set' folders\n",
        "# Please adjust these paths based on how your data unzips.\n",
        "# train_dir = 'train_set'\n",
        "# test_dir = 'test_set'\n",
        "\n",
        "# For demonstration, I will create dummy directories and images.\n",
        "# --- START: DUMMY DATA CREATION (Remove this in your real project) ---\n",
        "def create_dummy_data(base_dir, num_classes=3, num_images=20):\n",
        "    np.random.seed(42)\n",
        "    if not os.path.exists(base_dir):\n",
        "        os.makedirs(base_dir)\n",
        "    for i in range(num_classes):\n",
        "        class_dir = os.path.join(base_dir, f'class_{i}')\n",
        "        if not os.path.exists(class_dir):\n",
        "            os.makedirs(class_dir)\n",
        "        for j in range(num_images):\n",
        "            # Create a small dummy image\n",
        "            img_array = np.random.randint(0, 256, (64, 64, 3), dtype=np.uint8)\n",
        "            img = tf.keras.preprocessing.image.array_to_img(img_array)\n",
        "            img.save(os.path.join(class_dir, f'img_{j}.png'))\n",
        "\n",
        "train_dir = 'dummy_train'\n",
        "test_dir = 'dummy_test'\n",
        "create_dummy_data(train_dir, num_classes=3, num_images=50) # 3 classes, 50 images each for train\n",
        "create_dummy_data(test_dir, num_classes=3, num_images=20)  # 3 classes, 20 images each for test\n",
        "print(f\"Created dummy data in {train_dir} and {test_dir}\")\n",
        "# --- END: DUMMY DATA CREATION ---\n",
        "\n",
        "IMG_SIZE = (64, 64)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Load datasets from directories\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    label_mode='categorical', # Use 'categorical' for one-hot encoding\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    label_mode='categorical',\n",
        "    image_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False # Keep test data in order for evaluation\n",
        ")\n",
        "\n",
        "class_names = train_dataset.class_names\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(f\"Found classes: {class_names}\")\n",
        "\n",
        "# --- 3. Visualization (Select Techniques) ---\n",
        "print(\"\\n--- Visualizing Data ---\")\n",
        "\n",
        "# Technique 1: Show a batch of images (like a Scatter Plot for images)\n",
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[np.argmax(labels[i])])\n",
        "        plt.axis(\"off\")\n",
        "plt.suptitle(\"Batch of Training Images\")\n",
        "plt.savefig(\"image_batch_visualization.png\")\n",
        "plt.close()\n",
        "print(\"Saved image_batch_visualization.png\")\n",
        "\n",
        "# Technique 2: Bar Chart of Class Distribution\n",
        "# Note: This is harder with image_dataset_from_directory.\n",
        "# A simpler way is to count files in subdirectories.\n",
        "class_counts = []\n",
        "for class_name in class_names:\n",
        "    class_counts.append(len(os.listdir(os.path.join(train_dir, class_name))))\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(class_names, class_counts)\n",
        "plt.title(\"Training Data Class Distribution\")\n",
        "plt.ylabel(\"Number of Images\")\n",
        "plt.savefig(\"class_distribution_bar_chart.png\")\n",
        "plt.close()\n",
        "print(\"Saved class_distribution_bar_chart.png\")\n",
        "\n",
        "# --- 4. Preprocessing: Normalization & Imbalance Handling ---\n",
        "\n",
        "# 1. Normalization: Done as a layer in the model for efficiency\n",
        "normalization_layer = layers.Rescaling(1./255)\n",
        "\n",
        "# 2. Imbalance / Balance Handling (SMOTE/Oversampling)\n",
        "# This is complex with image generators.\n",
        "# A simpler method is to use 'class_weight' during model training.\n",
        "total_samples = sum(class_counts)\n",
        "class_weights = {}\n",
        "for i, count in enumerate(class_counts):\n",
        "    class_weights[i] = (1 / count) * (total_samples / NUM_CLASSES)\n",
        "print(f\"Calculated Class Weights for Imbalance: {class_weights}\")\n",
        "\n",
        "# Configure dataset for performance\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# --- 5. Machine Learning / Deep Learning Model (CNN) ---\n",
        "# A CNN is the correct choice for this image data.\n",
        "\n",
        "print(\"\\n--- Building CNN Model ---\")\n",
        "\n",
        "model = models.Sequential([\n",
        "    # Input layer with normalization\n",
        "    layers.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
        "    normalization_layer,\n",
        "\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Classifier Head\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.5), # Regularization\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax') # Output layer\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[\n",
        "        'accuracy',\n",
        "        tf.keras.metrics.Precision(name='precision'),\n",
        "        tf.keras.metrics.Recall(name='recall')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# --- 6. Train the Model ---\n",
        "print(\"\\n--- Training Model ---\")\n",
        "# Note: EPOCHS should be higher (e.g., 20-50) for a real dataset\n",
        "EPOCHS = 5\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=test_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    class_weight=class_weights, # Handle data imbalance\n",
        "    verbose=1 # Set to 1 to see progress\n",
        ")\n",
        "print(\"Model training complete.\")\n",
        "\n",
        "# --- 7. Evaluate Model & Metrics ---\n",
        "print(\"\\n--- Evaluating Model ---\")\n",
        "\n",
        "# Technique 3: Line Plot (Training/Validation Accuracy & Loss)\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range(EPOCHS), acc, label='Training Accuracy')\n",
        "plt.plot(range(EPOCHS), val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(EPOCHS), loss, label='Training Loss')\n",
        "plt.plot(range(EPOCHS), val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.suptitle(\"Model Training History\")\n",
        "plt.savefig(\"model_history_plot.png\")\n",
        "plt.close()\n",
        "print(\"Saved model_history_plot.png\")\n",
        "\n",
        "# Get predictions\n",
        "y_pred_probs = model.predict(test_dataset)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "# Get true labels\n",
        "y_true = []\n",
        "for images, labels in test_dataset:\n",
        "    y_true.extend(np.argmax(labels.numpy(), axis=1))\n",
        "\n",
        "# --- Metrics: Accuracy, Precision, Recall, F1-Score ---\n",
        "print(\"\\nClassification Report:\")\n",
        "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
        "print(classification_report(y_true, y_pred, target_names=class_names))\n",
        "\n",
        "# Overall Metrics\n",
        "print(f\"Overall Accuracy: {report['accuracy']:.4f}\")\n",
        "print(f\"Macro Avg Precision: {report['macro avg']['precision']:.4f}\")\n",
        "print(f\"Macro Avg Recall: {report['macro avg']['recall']:.4f}\")\n",
        "print(f\"Macro Avg F1-Score: {report['macro avg']['f1-score']:.4f}\")\n",
        "\n",
        "# --- Metrics: Confusion Matrix (Technique 4: Heatmap) ---\n",
        "print(\"\\nGenerating Confusion Matrix...\")\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 8))\n",
        "disp.plot(ax=ax, cmap='Blues', xticks_rotation='vertical')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"confusion_matrix.png\")\n",
        "plt.close()\n",
        "print(\"Saved confusion_matrix.png\")\n",
        "\n",
        "\n",
        "# --- Metrics: AUC-ROC Curve (Technique 5: Line Plot) ---\n",
        "# Binarize the labels for multiclass ROC\n",
        "y_true_bin = label_binarize(y_true, classes=range(NUM_CLASSES))\n",
        "\n",
        "# Calculate AUC\n",
        "try:\n",
        "    # 'macro' average is good for imbalance\n",
        "    auc_score = roc_auc_score(y_true_bin, y_pred_probs, average='macro', multi_class='ovr')\n",
        "    print(f\"\\nMacro-Average AUC Score: {auc_score:.4f}\")\n",
        "except ValueError as e:\n",
        "    print(f\"Could not calculate AUC score: {e}\")\n",
        "\n",
        "# Plot ROC Curve for each class\n",
        "plt.figure(figsize=(10, 7))\n",
        "for i in range(NUM_CLASSES):\n",
        "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_probs[:, i])\n",
        "    plt.plot(fpr, tpr, label=f'Class {class_names[i]} (AUC = {roc_auc_score(y_true_bin[:, i], y_pred_probs[:, i]):.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Chance')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Multiclass ROC Curve (One-vs-Rest)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"roc_auc_curve.png\")\n",
        "plt.close()\n",
        "print(\"Saved roc_auc_curve.png\")\n",
        "\n",
        "\n",
        "# --- 8. Next Steps (Ensemble, SHAP, Advanced DL) ---\n",
        "print(\"\\n--- Project Complete ---\")\n",
        "print(\"This script provides the foundation.\")\n",
        "print(\"Your next steps would be:\")\n",
        "print(\"1. Ensemble Models: Train other models (e.g., ResNet50, VGG16) and combine them.\")\n",
        "print(\"   - You can load pre-trained models from tf.keras.applications.\")\n",
        "print(\"2. Correlation/SHAP: SHAP for CNNs is very computationally expensive.\")\n",
        "print(\"   - It involves masking parts of images and re-running predictions thousands of times.\")\n",
        "print(\"   - Look into the 'shap' library's DeepExplainer for this advanced step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vGjU9dXQfP12",
        "outputId": "a4b52ef7-e67b-48bd-ca53-e4572afdf7d9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Setup Complete (Simulated for this environment) ---\n",
            "In a real environment (Colab), the above commands would download and unzip the data.\n",
            "Created dummy data in dummy_train and dummy_test\n",
            "Found 150 files belonging to 3 classes.\n",
            "Found 60 files belonging to 3 classes.\n",
            "Found classes: ['class_0', 'class_1', 'class_2']\n",
            "\n",
            "--- Visualizing Data ---\n",
            "Saved image_batch_visualization.png\n",
            "Saved class_distribution_bar_chart.png\n",
            "Calculated Class Weights for Imbalance: {0: 1.0, 1: 1.0, 2: 1.0}\n",
            "\n",
            "--- Building CNN Model ---\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8192\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m1,048,704\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │           \u001b[38;5;34m387\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8192</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,048,704</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,142,339\u001b[0m (4.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,339</span> (4.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,142,339\u001b[0m (4.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,142,339</span> (4.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Training Model ---\n",
            "Epoch 1/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 406ms/step - accuracy: 0.3005 - loss: 1.1693 - precision: 0.2872 - recall: 0.0927 - val_accuracy: 0.3333 - val_loss: 1.1018 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 316ms/step - accuracy: 0.3060 - loss: 1.1106 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3167 - val_loss: 1.0990 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 437ms/step - accuracy: 0.4103 - loss: 1.1003 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3000 - val_loss: 1.0983 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 253ms/step - accuracy: 0.3484 - loss: 1.0991 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3333 - val_loss: 1.0981 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/5\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 256ms/step - accuracy: 0.3740 - loss: 1.0875 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_accuracy: 0.3333 - val_loss: 1.0991 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Model training complete.\n",
            "\n",
            "--- Evaluating Model ---\n",
            "Saved model_history_plot.png\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class_0       0.00      0.00      0.00        20\n",
            "     class_1       0.33      1.00      0.50        20\n",
            "     class_2       0.00      0.00      0.00        20\n",
            "\n",
            "    accuracy                           0.33        60\n",
            "   macro avg       0.11      0.33      0.17        60\n",
            "weighted avg       0.11      0.33      0.17        60\n",
            "\n",
            "Overall Accuracy: 0.3333\n",
            "Macro Avg Precision: 0.1111\n",
            "Macro Avg Recall: 0.3333\n",
            "Macro Avg F1-Score: 0.1667\n",
            "\n",
            "Generating Confusion Matrix...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved confusion_matrix.png\n",
            "\n",
            "Macro-Average AUC Score: 0.5904\n",
            "Saved roc_auc_curve.png\n",
            "\n",
            "--- Project Complete ---\n",
            "This script provides the foundation.\n",
            "Your next steps would be:\n",
            "1. Ensemble Models: Train other models (e.g., ResNet50, VGG16) and combine them.\n",
            "   - You can load pre-trained models from tf.keras.applications.\n",
            "2. Correlation/SHAP: SHAP for CNNs is very computationally expensive.\n",
            "   - It involves masking parts of images and re-running predictions thousands of times.\n",
            "   - Look into the 'shap' library's DeepExplainer for this advanced step.\n"
          ]
        }
      ]
    }
  ]
}